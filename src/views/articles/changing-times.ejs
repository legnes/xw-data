<p>This post is all about how the puzzle's vocabulary changes over time. We'll look at how often new answers appear and what those new answers are, plus some old answers that aren't used as much anymore.</p>

<h3>Answer births</h3>

<p>As new words and phrases enter the language, some catch on and eventually find their way into your crossword puzzles. Here are some of the most recent answers to appear in the crossword.</p>

<table-loader data-id="mostRecentNewWords" data-src="api/figures/mostRecentNewWords">
  <form is="query-param-form">
    <label>minimum occurrences <input is="query-param-input" data-query-param="thresh" type="number" min="2" value="3"></label>
  </form>
</table-loader>

<p>Or you can use hindsight to pick out popular answers and ask "when was this introduced?". Here are the "top answers" from each year.</p>

<table-loader data-id="topNewWordsByYear" data-src="api/figures/topNewWordsByYear"></table-loader>

<p>Almost all of the ususal word birth patterns are represented. There are neologisms (DADBOD, BAE, SELFIE), loanwords (NIHAO, BENTO, ASANAS), acronyms (EGOT, RBG, IPAS), abbreviations (MICS, OLINE, APBIO), and portmanteaus/affixes (MATHLETE, ENEWS, BREXIT). Find your favorites!</p>

<h3>Answer deaths</h3>

<p>Just as new words enter a language, old words also die out. Here's a list of once-common answers that disappeared some time ago.</p>

<table-loader data-id="oldestDeadWords" data-src="api/figures/oldestDeadWords">
  <form is="query-param-form">
    <label>minimum occurrences <input is="query-param-input" data-query-param="thresh" type="number" min="2" value="10"></label>
  </form>
</table-loader>

<p>There are a few age-outs. Evidently ZASU Pitt, SHANA Alexander, ILKA Chase, and Virna LISI aren't as famous as they once were. Some changes are probably editorial decisions: MASSA and KKK haven't been used for fill since 2002. But many dead answers are simply obscure trivia like BAUD, SARTO, and CEBU.</p>

<p>A look at dying answers begs the question: how long do answers usually live for?</p>

<graph-loader data-id="wordLongevity" data-src="api/figures/wordLongevity">
  <form is="query-param-form">
    <label>minimum occurrences <input is="query-param-input" data-query-param="thresh" type="number" min="1" value="1"></label>
  </form>
</graph-loader>

<p>Of course many answers have only ever been used once, but a surprising number stick around!</p>

<h3>The dictionary</h3>

<p>The dictionary of "all answers ever used since the beginning of time" is constantly growing.</p>

<graph-loader data-id="uniqueAnswersOverTime" data-src="api/figures/uniqueAnswersOverTime">
  <graph-log-axis-checkbox></graph-log-axis-checkbox>
</graph-loader>

<p>This curve is a little remeniscent of Herdan's (or Heaps') law. In a 1960 book, Gustav Herdan noticed a pattern in type-token distributions. Remember that a handful of answers appear in the puzzle very often, while a large number of words only appear once or twice. As you go through the corpus puzzle by puzzle, keeping track of which answers you've seen, you'd expect to come across a lot of the high-frequency answers pretty quickly, but it'll take longer to find all the low-frequency answers. That's essentially what Herdan's law is getting at. Qualitativley it says you'll find new answers very quickly at first, and then more slowly and steadily later. Quantitatively, it says:</p>

<p><em>V = kN<sup>h</sup></em></p>

<p>where <em>V</em> is the size of the vocabulary, the number of unique answers you've come across, <em>N</em> is the size of the corpus, the total number of answers in all the puzzles you've looked at, and <em>k</em> and <em>h</em> are experimental constants, where <em>h</em> is usually less than 1. It's worth noting that in theory Herdan's law applies to any subdivision of a corpus <a href="#ref1">[1]</a>. So for example if you had a corpus of encyclopedia articles, you could look at unique words vs. total words <em>for each article separately</em>, rather than accumulating across articles. But subdividing over time works too!</p>

<p>So if the dictionary of possible answers is steadily increasing, has the variety of answers gone up with it? The NYT crossword is a daily publication with regular sizing and a maximum number of answers in any given puzzle, so its vocabulary shouldn't vary too wildly. Here are unique answers used in each day/month/year.</p>

<graph-loader data-id="dictionarySizeOverTime" data-src="api/figures/dictionarySizeOverTime">
  <form is="query-param-form">
    <span>timescale:</span><br />
    <span>&emsp;</span><label>years<input is="query-param-input" data-query-param="timescale" type="radio" name="timescale" value="year"></label><br />
    <span>&emsp;</span><label>months<input is="query-param-input" data-query-param="timescale" type="radio" name="timescale" value="month" checked></label><br />
    <span>&emsp;</span><label>days<input is="query-param-input" data-query-param="timescale" type="radio" name="timescale" value="day"></label><br />
  </form>
</graph-loader>

<p>If you zoom in on the days, you'll see a spike every Sunday when the grid is bigger. Overall it seems like there was a bit more variety in puzzle vocabulary around 2012-13, but it's gone back down again since then. Partly that's because, just as answers are "born", they also "die out". Here are answer births and deaths over time.</p>

<graph-loader data-id="countBirthsDeathsOverTime" data-src="api/figures/countBirthsDeathsOverTime">
  <graph-log-axis-checkbox data-axes="y"></graph-log-axis-checkbox>
  <form is="query-param-form">
    <label>minimum occurrences <input is="query-param-input" data-query-param="thresh" type="number" min="1" value="1"></label><br />
    <span>timescale:</span><br />
    <span>&emsp;</span><label>years<input is="query-param-input" data-query-param="timescale" type="radio" name="timescale" value="year"></label><br />
    <span>&emsp;</span><label>months<input is="query-param-input" data-query-param="timescale" type="radio" name="timescale" value="month" checked></label><br />
    <span>&emsp;</span><label>days<input is="query-param-input" data-query-param="timescale" type="radio" name="timescale" value="day"></label><br />
  </form>
</graph-loader>

<p>This graph is a little hard to read because of Herdan's law -- births happen very quickly as you first start looking at puzzles, and deaths happen quickly for the same reason later on. It's hard to tell if birth and death rates have changed over time. One way to see through the steep curve is with random shufflings <a href="#ref1">[1]</a>. If you were to shuffle up the puzzles, pretending they were published in a different order than they really were, you'd get a slightly different graph of answer births over time. If you averaged the birth rates of every possible shuffling, you'd get a statistically expected birth curve. Then you could compare your <em>actual</em> curve to the expected one. I haven't done this analysis myself, but if you're interested, you can read more <a href="https://royalsocietypublishing.org/doi/10.1098/rsos.200008">here</a>!</p>

<p>One reason we care about birth and death rates is that they tell us about our society. Language change happens faster during wartime and correlates to social and technological trends, local cultural factors, etc. <a href="#ref2">[2]</a> <a href="#ref3">[3]</a>.</p>

<p>Another reason we care about the birth rate is that it tells us how often we see brand new answers cropping up in the puzzle! Turns out it's a lot, easily 5-10 new answers a day. Let's thank our constructors once again for their endless creativity!</p>

<h3>Caveats</h3>

<p>I wanted to mention that the relationship between frequency distribution and Herdan's law is pretty complicated, and the mathematical form of Herdan's law is itself contested <a href="#ref1">[1]</a> <a href="#ref5">[5]</a>. I may have oversimplified a bit.</p>

<p>Also, there's plenty of other good reading out there about language change. One issue with the crossword corpus is its relatively short time scale. One paper discusses how to look at patterns of language change within/among young, highly volatile online communities <a href="#ref4">[4]</a>. For the complete opposite -- a consideration of massive amounts of data over extremely long timescales, a bunch of researchers got together and published a great paper when Google Books was first released <a href="#ref6">[6]</a>.</p>

<p>That's all!</p>

<h3>References</h3>

<p id="ref1">[1] <a href="https://royalsocietypublishing.org/doi/10.1098/rsos.200008">Chacoma A. and Zanette D. H. 2020. Heaps’ Law and Heaps functions in tagged texts: evidences of their linguistic relevance. R. Soc. open sci.7200008200008</a></p>
<p id="ref2">[2] <a href="https://www.nature.com/articles/srep00313">Petersen, A., Tenenbaum, J., Havlin, S. et al. Statistical Laws Governing Fluctuations in Word Use from Word Birth to Word Death. Sci Rep 2, 313 (2012). https://doi.org/10.1038/srep00313</a></p>
<p id="ref3">[3] <a href="http://colala.berkeley.edu/papers/piantadosi2014zipfs.pdf">Piantadosi, Steven T. “Zipf's word frequency law in natural language: a critical review and future directions.” Psychonomic bulletin & review vol. 21,5 (2014): 1112-30. doi:10.3758/s13423-014-0585-6</a></p>
<p id="ref4">[4] <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0019009">Altmann EG, Pierrehumbert JB, Motter AE (2011) Niche as a Determinant of Word Fate in Online Groups. PLoS ONE 6(5): e19009.</a></p>
<p id="ref5">[5] <a href="https://arxiv.org/abs/1412.4577">Font-Clos, Francesc, and Álvaro, Corral. "Log-Log Convexity of Type-Token Growth in Zipf’s Systems".Physical Review Letters 114, no.23 (2015).</a></p>
<p id="ref6">[6] <a href="http://www.uvm.edu/pdodds/research/papers/others/2010/michel2010a.pdf">Michel, Jean-Baptiste, Yuan Kui, Shen, Aviva Presser, Aiden, Adrian, Veres, Matthew K., Gray, , Joseph P., Pickett, Dale, Hoiberg, Dan, Clancy, Peter, Norvig, Jon, Orwant, Steven, Pinker, Martin A., Nowak, and Erez Lieberman, Aiden. "Quantitative Analysis of Culture Using Millions of Digitized Books".Science 331, no.6014 (2011): 176–182.</a></p>
