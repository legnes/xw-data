<p>We take a look at new answers to make the crossword and old standards that no longer see use.</p>

<h3>The dictionary</h3>

<p>It can be easy to harp on the answers we see over and over in the puzzle. But what about <em>new</em> answers? How fast is the crossword puzzle's dictionary growing?</p>

<graph-loader data-id="uniqueAnswersOverTime" data-src="api/figures/uniqueAnswersOverTime">
  <graph-log-axis-checkbox></graph-log-axis-checkbox>
</graph-loader>

<p>This curve is a little remeniscent of Herdan's (or Heaps') law. Remember that a handful of answers appear in the puzzle very often, and a large number of words only appear once or twice. As we go through the corpus puzzle by puzzle, keeping track of which answers we've seen, we'd expect to come across a lot of the high-frequency answers pretty quickly, but for it to take a while for us to find all the low-frequency answers. That's essentially what Herdan's law is getting at. Qualitativley it says we'll find new answers very quickly at first, and then slower and more steadily later. Quantitatively, it says:</p>

<p><em>V = kN<sup>h</sup></em></p>

<p>where <em>V</em> is the size of the vocabulary, the number of unique answers we've come across, <em>N</em> is the size of the corpus, the total number of answers in all the puzzles we've looked at, and <em>k</em> and <em>h</em> are experimental constants, where <em>h</em> is usually less than 1. It's worth noticing that Herdan's law applies to any subdivision of a corpus. So for example if we had a corpus of encyclopedia articles, we could look at unique words vs. total words <em>for each article separately</em>, rather than accumulating across articles <a href="#ref1">[1]</a>. But subdividing over time works too!</p>

<p>So if the pool of answers is steadily increasing, has the variety of answers gone up with it? Due to the NYT crossword's daily publication, regular sizing, and maximum number of answers in any given puzzle, its vocabulary shouldn't vary too wildly. But in theory constructors have more answers to choose from, right?</p>

<graph-loader data-id="dictionarySizeOverTime" data-src="api/figures/dictionarySizeOverTime">
  <form is="query-param-form">
    <span>timescale:</span><br />
    <span>&emsp;</span><label>years<input is="query-param-input" data-query-param="timescale" type="radio" name="timescale" value="year"></label><br />
    <span>&emsp;</span><label>months<input is="query-param-input" data-query-param="timescale" type="radio" name="timescale" value="month" checked></label><br />
    <span>&emsp;</span><label>days<input is="query-param-input" data-query-param="timescale" type="radio" name="timescale" value="day"></label><br />
  </form>
</graph-loader>

<p>It doesn't seem like there's any strong trend. Partly that's because, just as answers are "born", they also "die out". Here are answer births and deaths over time.</p>

<graph-loader data-id="countBirthsDeathsOverTime" data-src="api/figures/countBirthsDeathsOverTime">
  <graph-log-axis-checkbox data-axes="y"></graph-log-axis-checkbox>
  <form is="query-param-form">
    <label>lifetime usage threshold <input is="query-param-input" data-query-param="thresh" type="number" min="1" value="1"></label><br />
    <span>timescale:</span><br />
    <span>&emsp;</span><label>years<input is="query-param-input" data-query-param="timescale" type="radio" name="timescale" value="year"></label><br />
    <span>&emsp;</span><label>months<input is="query-param-input" data-query-param="timescale" type="radio" name="timescale" value="month" checked></label><br />
    <span>&emsp;</span><label>days<input is="query-param-input" data-query-param="timescale" type="radio" name="timescale" value="day"></label><br />
  </form>
</graph-loader>

<p>This graph is a little hard to read because of Herdan's law -- the dictionary grows very quickly at first, and it decays very quickly for the same reason. It's hard to tell if birth and death rates have changed over time. One way to see through the steep curve is with random shufflings. If we were to shuffle up the puzzles, pretending they were published in a different order than they really were, we'd get a slightly different graph of answer births over time. If we repeatedly shuffled the puzzles and averaged their birth curves, we'd get a statistically "expected" birth curve. Then we could compare our <em>actual</em> curve to the expected one <a href="#ref1">[1]</a> (similar analysis, TODO reread this) (TODO do this analysis?).</p>

<p>One reason we care about birth and death rates is that they tell us about our society. Languages change faster during wartime, and correlates to social and technological trends, local cultural factors, etc. <a href="#ref2">[2]</a> <a href="#ref3">[3]</a>.</p>

<p>Another reason we care about the birth rate is that it tells us how often we see brand new answers cropping up in the puzzle. And it's a lot, easily 5-10 new answers a day! Let's take a look at some of the answers that have come and gone.</p>

<h3>Answer deaths</h3>

<p>Here's a list of once-common answers that disappeared some time ago.</p>

<table-loader data-id="oldestDeadWords" data-src="api/figures/oldestDeadWords">
  <form is="query-param-form">
    <label>lifetime usage threshold <input is="query-param-input" data-query-param="thresh" type="number" min="2" value="3"></label>
  </form>
</table-loader>

<p>There are a few interesting cases - ALAR and SDI haven't been in the news for decades, and evidently constructors stopped using MASSA and KKK for fill in 2002. But many are simply obscure trivia like BAUD, SARTO, and CEBU. A look at dying answers begs the question: how long do answers usually live for?</p>

<graph-loader data-id="wordLongevity" data-src="api/figures/wordLongevity">
  <form is="query-param-form">
    <label>lifetime usage threshold <input is="query-param-input" data-query-param="thresh" type="number" min="1" value="1"></label>
  </form>
</graph-loader>

<h3>Answer births</h3>

<p>Here's the flip side: most recent answers to be introduced.</p>

<table-loader data-id="mostRecentNewWords" data-src="api/figures/mostRecentNewWords">
  <form is="query-param-form">
    <label>lifetime usage threshold <input is="query-param-input" data-query-param="thresh" type="number" min="2" value="3"></label>
  </form>
</table-loader>

<p>And for another angle, here are the "top answers" from each year.</p>

<table-loader data-id="topNewWordsByYear" data-src="api/figures/topNewWordsByYear">
  <form is="query-param-form">
    <label>lifetime usage threshold <input is="query-param-input" data-query-param="thresh" type="number" min="2" value="3"></label>
  </form>
</table-loader>

<p>Almost all of the ususal word birth patterns are represented. There are neologisms (DADBOD, BAE, SELFIE), loanwords (NIHAO, BENTO, ASANAS), acronyms (EGOT, RBG, IPAS), abbreviations (MICS, OLINE, APBIO), and portmanteaus/affixes (MATHLETE, ENEWS, BREXIT). Find your favorites!</p>

<h3>Caveats</h3>

<p>One thing to note is that the relationship between frequency distribution and Herdan's law is pretty complicated, and the mathematical form of Herdan's law is itself contested, so I oversimplified a lot in this article <a href="https://arxiv.org/abs/1412.4577">[REF]</a> <a href="#ref1">[1]</a>.</p>

<p>The only other thing to mention is that there's plenty of other good reading out there about language change. One issue with the crossword corpus is its relatively short time scale. One paper discusses how to look at patterns of language change within/among young, highly volatile online communities <a href="#ref4">[4]</a>. For the complete opposite -- a consideration of massive amounts of data over extremely long timescales, a bunch of researchers got together and published a great paper when Google Books was first released <a href="#ref5">[5]</a>.</p>

<p>That's all!</p>

<h3>References</h3>

<p id="ref1">[1] <a href="https://royalsocietypublishing.org/doi/10.1098/rsos.200008">Chacoma A. and Zanette D. H. 2020. Heaps’ Law and Heaps functions in tagged texts: evidences of their linguistic relevance. R. Soc. open sci.7200008200008</a></p>
<p id="ref2">[2] <a href="https://www.nature.com/articles/srep00313">Petersen, A., Tenenbaum, J., Havlin, S. et al. Statistical Laws Governing Fluctuations in Word Use from Word Birth to Word Death. Sci Rep 2, 313 (2012). https://doi.org/10.1038/srep00313</a></p>
<p id="ref3">[3] <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4176592/">Piantadosi, Steven T. “Zipf's word frequency law in natural language: a critical review and future directions.” Psychonomic bulletin & review vol. 21,5 (2014): 1112-30. doi:10.3758/s13423-014-0585-6</a></p>
<p id="ref4">[4] <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0019009">Altmann EG, Pierrehumbert JB, Motter AE (2011) Niche as a Determinant of Word Fate in Online Groups. PLoS ONE 6(5): e19009.</a></p>
<p id="ref5">[5] <a href="http://www.uvm.edu/pdodds/research/papers/others/2010/michel2010a.pdf">Michel, Jean-Baptiste, Yuan Kui, Shen, Aviva Presser, Aiden, Adrian, Veres, Matthew K., Gray, , Joseph P., Pickett, Dale, Hoiberg, Dan, Clancy, Peter, Norvig, Jon, Orwant, Steven, Pinker, Martin A., Nowak, and Erez Lieberman, Aiden. "Quantitative Analysis of Culture Using Millions of Digitized Books".Science 331, no.6014 (2011): 176–182.</a></p>
