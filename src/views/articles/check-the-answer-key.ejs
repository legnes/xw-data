<p>In this post, we'll be using keyness to differentiate crosswordese from bad fill. For more information on keyness, check out Costas Gabrielatos's phenomenal chapter <a href="https://core.ac.uk/download/pdf/227092349.pdf">[REF]</a> in Corpus Approaches to Discourse <a href="https://books.google.com/books/about/Corpus_Approaches_to_Discourse.html?id=-M1JDwAAQBAJ">[REF]</a>, edited by Charlotte Taylor and Anna Marchi. I owe pretty much everything in this post to Gabrielatos's explanation. The implementation is all my own; if you're looking to do something similar, I got a lot of help from <a href="http://ucrel.lancs.ac.uk/llwizard.html">this log-likelihood wizard</a> put out by Paul Rayson and UCREL at Lancaster University, as well as <a href="https://alvinntnu.github.io/NTNU_ENC2036_LECTURES/keyword-analysis.html">this chapter</a> from Alvin Chen's National Taiwan Normal University course on corpus linguistics.</p>

<h3>Relative frequency</h3>

<p>So-called <a href="https://en.wikipedia.org/wiki/Crosswordese">crosswordese</a> and <a href="https://www.nytimes.com/2018/06/13/crosswords/how-to-make-a-crossword-fill.html#:~:text=bad%20fill">bad fill</a> plague much of crossword-land, and the NYT puzzle is no exception. But what <em>is</em> crosswordese? What makes certain answers feel a little cheesy or unfair?</p>

<p>Crosswordese isn't just <a href="/short-answer-is#mostFrequentAnswers">the most common crossword answers</a>. What feels cheesy is when a word appears often in crosswords but relatively rarely in normal english. A word's <em>relative frequency</em> is how many times it shows up in a corpus, divided by the total number of words in that corpus. Crosswordese happens when there's a big difference between a word's relative frequency in crosswords and its relative frequency in english.</p>

<table-loader data-id="relativeFrequencyDifference" data-src="api/figures/relativeFrequencyDifference">
  <form is="query-param-form">
    <label>only positive values <input is="query-param-input" data-query-param="positive" type="checkbox"></label>
  </form>
</table-loader>

<p>This is a table of words with large differences in relative frequencies. Mostly they're grammatically useful words like articles, conjunctions, and prepositions. We should've expected as much. These are words that show up all over the place in normal english, but don't make very good crossword answers. Crossword answers don't usually connect gramatically the same way english words do, and anyway a lot of these would be really hard to clue. There are also a couple of two-letter words that <a href="https://www.nytimes.com/puzzles/submissions/crossword">according to the Times' rules</a> aren't allowed to be crossword answers.</p>

<p>Words with <em>negative</em> values in the "difference in relative frequency" column are more common in english than they are in crosswords. That's pretty much the entire table right now. What we care about are words that have a <em>positive</em> difference, which you can see by checking the "only positive values" box and reloading the data. A group of likely crosswordese suspects pops right up: three-to-four-letters, vowel-heavy.</p>

<p>(As an aside, you might think words like ERA that show up semi-medium-often-ish in normal english would have a lower relative frequency difference. So why is ERA topping the list? It's because word frequency is nonlinear. The most frequent words are disproportionately more common than less frequent words. If ERA is the most common crossword answer but only, say, the 1000<sup>th</sup> most common english word, its crossword relative frequency will dwarf its english relative frequency. Check out <a href="">the post on Zipf's law</a> for more!)</p>

<p>Also, a note about the reference corpus: I'm using a frequency list of <a href="https://github.com/IlyaSemenov/wikipedia-word-frequency">english words from wikipedia articles</a> scraped in 2019. It'll produce different results than, say, a corpus of newspaper articles or of science fiction novels. Likely its style is pretty formal but with a lot of variation. It'll also probably skew towards people, places, institutions, acronyms, and in general the kind of thing you'd write a wikipedia article about.</p>

<h3>Keyness</h3>

<p>Relative frequency is a pretty crude metric. Let's get a more nuanced picture. Keyness combines effect-size measures with statistical measures. <strong>Effect-size measures</strong> tell us <em>how big</em> the difference is in a word's frequency between two corpora. Relative frequency is an effect-size measure. <strong>Statistical measures</strong> tell us <em>how reliable</em> the difference is. The chi-squared test, for example, is a statistical measure. A big difference in frequency doesn't mean much if it happened by total chance. Then again, a statistically significant usage pattern isn't worth looking at unless it's interesting too.</p>

<p>Put it all together and you get keyness. We'll use a statistical metric to select only statistically significant results, and then sort them based on an effect-size metric, like this:</p>

<!-- <p>(A quick aside. I just wanted to mention that keyness can help contribute to the broader study of <strong>aboutness</strong>, i.e. the subject of a given document. Documents about different things should have statistically significant keywords with respect to each other, or with respect to a reference corpus. So while we're going around looking at keyness, we can in theory keep an eye out for what crosswords are "about". That said, keyness is just one factor in aboutness; things like collocation area also super important. Another common theme surrounding keyness is whether you take a focused or an exploratory approach. A focused approach will evaluate the keyness of certain words/features of interest. We will be tending towards an exploratory approach, in which we evaluate keyness across all word types in the corpus and try to draw conclusions from there.)</p> -->

<table-loader data-id="keyness" data-src="api/figures/keyness">
  <form is="query-param-form">
    <label>frequency threshold for english corpus <input is="query-param-input" data-query-param="enFreqThresh" type="number" min="1" value="1"></label><br />
    <label>word length threshold <input is="query-param-input" data-query-param="lengthThresh" type="number" min="0" value="1"></label><br />
    <label>sameness (lowest log ratios) <input is="query-param-input" data-query-param="sameness" type="checkbox"></label><br />
  </form>
</table-loader>

<p>What comes out is a very different list of answers. Most of them <em>aren't really english words at all</em> -- they're loanwords, abbreviations, phrases, etc. And weird ones at that! Brands like ELAL and EDYS, french words like ETES and ETRE, proper nouns like OHARE and RELEE (yikes), phrases like IBET, and double whammies like borrowed phrases ELTORO and INRE. Abbreviations like RTES. Jargon like ALIENEE (woof). Irregular uses of affixes like RETAG, ACMES, and ANEAR.</p>

<p>(An aside on how to read the table: "log ratio" and "difference coefficient" are effect-size metrics. For every point of log ratio, a word appears (relatively) twice as many times in one corpus or the other. A log ratio of +14 means a word is about 16,000 times as common in the crossword as in english. "Difference coefficient" is the same as the difference in relative frequency from earlier, only normalized by the combined relative frequencies in the two corpora (so, difference over sum). Normalizing is helpful because it lets us see past the most common words in each corpus. The statistical metrics are "log likelihood G2" and "bayes factor". A strong G<sup>2</sup> value is around 19, and a value of 23 is overwhelming. A strong Bayes factor (or BIC) is around 6, and 10 is overwhelming. We're filtering out anything with a Bayes factor <= 2.)</p>

<p>A clever grid gently locks into place with a satisfying click. Around bad fill, the grid groans and creaks under visible strain. It's tiring to see the same words over and over again in the puzzle, but it's worse when those words are so irregular or obscure that you were never going to think of them without guessing from the crosses. If relative frequency showed us some of the more <em>boring</em> crosswordese answers, I think keyness is showing us some of the more <em>egregious</em> ones. Answers where you go <em>"that's not a word!"</em> or <em>"EVENER!? Come on!"</em>. These, to me, are some of the real feel-bad answers.</p>

<h3>Cluing keywords</h3>

<p>Bad fill is hard to clue. Disclaimer: this is just a theory and I haven't tested it at all. But I've noticed that some very common answers can be clued in a bunch of creative ways. ERA can be a time period, a baseball statistic, a proposed constitutional amendment, or even a laundry detergent. Keyword answers, on the other hand...well, check out the clues for ALIENEE:</p>

<table-loader data-id="answerClues" data-src="api/figures/answerClues">
  <form is="query-param-form">
    <label>answer <input is="query-param-input" data-query-param="search" type="text" value="alienee"></label>
  </form>
</table-loader>

<p>Pretty much word-for-word the same since its first appearance in 1996. ELEE is almost always "waiting for the ___" or "gen. robt. ___". ANEAR is "close" or "lend ___" (AN EAR). Sometimes it's fun to look at a clue and jump to conclusions: <em>"okay, it's gotta be NAVE or APSE!"</em>. But maybe if we as constructors feel <em>forced</em> to use a tired clue, it's a sign of bad fill.</p>

<h3>Keyness variables</h3>

<p>I included some little knobs and switches underneath the keyness table. One is an english frequency threshold. It's hepful for looking at keywords that are <em>definitely</em> also english words. If you crank it up to 150, you'll still get some proper nouns (ESTEE), borrowings (ERAT), etc. And as usual you'll find short vowelly words (OLIO, OLEO, EDAM). But you'll also notice old words (ANON, AGUE), semantically niche words (EPEE, STET, SLOE), and words that just wouldn't show up very much in wikipedia (EMOTE, OAF). At threshold 500 you find a lot of abbreviations (ENE, ENS). By threshold 1000, you're into unusual nouns (ALOE, OAT, ETNA) as well as reverse keywords (DISTRICT, INTERNATIONAL, JANUARY).</p>

<p>There's also an input for answer length and one for "sameness". As you'd expect, upping the length threshold reveals a lot of phrases and names (IRONORE, ENMASSE, RIOTACT, NESTEGG, BONJOVI). Sameness filters for words with high Bayes factors but low log ratios. It seems to come up with generic words (OLD, EVER, UPON). These high-sameness words cry out for grammatical and semantic analysis - is it same-old length and letters, or is there some other trait that makes a common english word good for the crossword? But let's save that for another time.</p>

<h3>Keyness over time</h3>

<p>There's one last sort of neat thing we can do with keyness. By analyzing each year's puzzles against the whole crossword corpus, we can look at which answers were key in a given year:</p>

<table-loader data-id="keynessPerYear" data-src="api/figures/keynessPerYear"></table-loader>

<p>Notice that the statistical metrics are a lot lower, which makes sense because the sample sizes are a lot smaller. So it's not exactly a statistical fact that ANAGRAMS were super trendy in 2014 or that 2016 got really into ROMCOMs. But it's a fun way to look at cultural trends and to track the spread of neologisms. For more, check out the <a href="">post on language change!</a></p>

<p>Any caveats? That's all for this post.</p>
